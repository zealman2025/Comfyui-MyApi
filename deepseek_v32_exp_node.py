import os
import json
import traceback

try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False


def load_deepseek_models_from_config():
    """ä»config.jsonåŠ è½½DeepSeekæ¨¡å‹é…ç½®"""
    try:
        config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "config.json")
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        models = config.get("models", {})
        deepseek_models = models.get("deepseek", {})
        return deepseek_models if deepseek_models else {
            "deepseek-chat": "DeepSeek Chat",
            "deepseek-reasoner": "DeepSeek Reasoner",
        }
    except Exception as e:
        print(f"[DeepSeekV32ExpNode] åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
        traceback.print_exc()
        return {
            "deepseek-chat": "DeepSeek Chat",
            "deepseek-reasoner": "DeepSeek Reasoner",
        }


DEEPSEEK_MODELS = load_deepseek_models_from_config()


class DeepSeekV32ExpNode:
    """DeepSeek V3.2 Experimental èŠå¤©èŠ‚ç‚¹"""

    CATEGORY = "ğŸMYAPI"
    RETURN_TYPES = ("STRING",)
    FUNCTION = "process"

    def __init__(self):
        self.config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "config.json")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "model": (list(DEEPSEEK_MODELS.keys()), {"default": "deepseek-chat"}),
                "prompt": ("STRING", {"multiline": True, "default": "ä½ å¥½ï¼ŒDeepSeek!"}),
            },
            "optional": {
                "system_prompt": ("STRING", {"multiline": True, "default": "You are a helpful assistant."}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0}),
                "max_tokens": ("INT", {"default": 2048, "min": 1, "max": 8192}),
                "top_p": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}),
                "stream": ("BOOLEAN", {"default": False}),
            },
        }

    def _get_api_key(self, input_api_key: str) -> str:
        invalid_placeholders = {
            "YOUR_API_KEY",
            "ä½ çš„apikey",
            "your_api_key_here",
            "è¯·è¾“å…¥APIå¯†é’¥",
            "è¯·è¾“å…¥ä½ çš„APIå¯†é’¥",
            "",
        }

        if input_api_key and input_api_key.strip() and input_api_key.strip() not in invalid_placeholders:
            print("[DeepSeekV32ExpNode] ä½¿ç”¨è¾“å…¥çš„APIå¯†é’¥")
            return input_api_key.strip()

        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                config = json.load(f)
            config_key = config.get("deepseek_api_key", "").strip()
            if config_key:
                print("[DeepSeekV32ExpNode] ä½¿ç”¨config.jsonä¸­çš„APIå¯†é’¥")
            else:
                print("[DeepSeekV32ExpNode] config.jsonä¸­æœªæ‰¾åˆ°deepseek_api_key")
            return config_key
        except Exception as e:
            print(f"[DeepSeekV32ExpNode] è¯»å–config.jsonå¤±è´¥: {str(e)}")
            traceback.print_exc()
            return ""

    def _check_dependencies(self):
        missing = []
        if not HAS_OPENAI:
            missing.append("openai")
        return missing

    def process(self, api_key, model, prompt, system_prompt="You are a helpful assistant.", temperature=1.0,
                max_tokens=2048, top_p=1.0, stream=False):
        missing = self._check_dependencies()
        if missing:
            return (f"Error: è¯·å®‰è£…ä¾èµ– {', '.join(missing)}ï¼Œä¾‹å¦‚è¿è¡Œ pip install openai",)

        actual_key = self._get_api_key(api_key)
        if not actual_key:
            return ("Error: æœªæ‰¾åˆ°æœ‰æ•ˆçš„APIå¯†é’¥ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥æˆ–åœ¨config.jsonä¸­é…ç½®deepseek_api_keyã€‚",)

        try:
            client = OpenAI(api_key=actual_key, base_url="https://api.deepseek.com")

            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})

            response_text = ""

            if stream:
                completion = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    top_p=top_p,
                    stream=True,
                )

                for chunk in completion:
                    if chunk.choices and chunk.choices[0].delta:
                        delta_content = chunk.choices[0].delta.content or ""
                        response_text += delta_content
                return (response_text,)

            completion = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                top_p=top_p,
                stream=False,
            )

            if completion.choices:
                response_text = completion.choices[0].message.content or ""
            return (response_text,)

        except Exception as e:
            print(f"[DeepSeekV32ExpNode] è°ƒç”¨DeepSeekå¤±è´¥: {str(e)}")
            traceback.print_exc()
            return (f"Error: {str(e)}",)


NODE_CLASS_MAPPINGS = {
    "DeepSeekV32ExpNode": DeepSeekV32ExpNode,
}


NODE_DISPLAY_NAME_MAPPINGS = {
    "DeepSeekV32ExpNode": "ğŸ­DeepSeek V3.2 Exp",
}

