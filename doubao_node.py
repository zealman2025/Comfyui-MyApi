import os
import json
import folder_paths
import io
import base64
import traceback
import time
import random
import string

# å°è¯•å¯¼å…¥ä¾èµ–ï¼Œä½†ä¸å¼ºåˆ¶è¦æ±‚
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False

try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False

try:
    import torch
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False

try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False

# ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹é…ç½®
def load_models_from_config():
    """ä»config.jsonåŠ è½½æ¨¡å‹é…ç½®"""
    try:
        config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "config.json")

        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            models = config.get('models', {})
            doubao_models = models.get('doubao', {})
            return doubao_models
    except Exception as e:
        print(f"[DoubaoMMM] Error loading models from config: {str(e)}")
        import traceback
        traceback.print_exc()
        # æä¾›é»˜è®¤æ¨¡å‹ä½œä¸ºå›é€€
        default_models = {
            "doubao-seed-1-6-vision-250815": "doubao-seed-1-6-vision-250815",
            "doubao-seed-1-6-251015": "doubao-seed-1-6-251015",
            "doubao-seed-1-8-251215": "doubao-seed-1-8-251215"
        }
        print(f"[DoubaoMMM] Using default models: {default_models}")
        return default_models

# åŠ è½½æ¨¡å‹é…ç½®
DOUBAO_MODELS = load_models_from_config()

class DoubaoNode:
    def __init__(self):
        self.current_seed = 0  # åˆå§‹åŒ–ç§å­å€¼
        self.config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "config.json")

    def _get_api_key(self, input_api_key):
        """è·å–APIå¯†é’¥ï¼Œä¼˜å…ˆä½¿ç”¨è¾“å…¥çš„å¯†é’¥ï¼Œå¦åˆ™ä»config.jsonè¯»å–"""
        # å®šä¹‰æ— æ•ˆçš„å ä½ç¬¦æ–‡æœ¬
        invalid_placeholders = [
            "YOUR_API_KEY",
            "ä½ çš„apikey",
            "your_api_key_here",
            "è¯·è¾“å…¥APIå¯†é’¥",
            "è¯·è¾“å…¥ä½ çš„APIå¯†é’¥",
            ""
        ]

        # å¦‚æœè¾“å…¥äº†æœ‰æ•ˆçš„APIå¯†é’¥ï¼Œä¼˜å…ˆä½¿ç”¨
        if (input_api_key and
            input_api_key.strip() and
            input_api_key.strip() not in invalid_placeholders):
            print(f"[DoubaoMMM] ä½¿ç”¨è¾“å…¥çš„APIå¯†é’¥")
            return input_api_key.strip()

        # å¦åˆ™ä»config.jsonè¯»å–
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                config_api_key = config.get('doubao_api_key', '').strip()
                if config_api_key:
                    print(f"[DoubaoMMM] ä½¿ç”¨config.jsonä¸­çš„APIå¯†é’¥")
                    return config_api_key
                else:
                    print(f"[DoubaoMMM] config.jsonä¸­æœªæ‰¾åˆ°doubao_api_key")
                    return ''
        except Exception as e:
            print(f"[DoubaoMMM] è¯»å–config.jsonå¤±è´¥: {str(e)}")
            return ''

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"default": "", "multiline": False}),
                "model": (list(DOUBAO_MODELS.keys()),),
                "prompt": ("STRING", {"multiline": True, "default": "å›¾ç‰‡ä¸»è¦è®²äº†ä»€ä¹ˆ?"}),
                "max_completion_tokens": ("INT", {"default": 65535, "min": 1, "max": 65535}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0}),
                "top_p": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0x7fffffff}),
                "reasoning_effort": (["minimal", "low", "medium", "high"], {"default": "minimal"}),
            },
            "optional": {
                "image": ("IMAGE",),
                "image_2": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING",)
    FUNCTION = "process"
    CATEGORY = "ğŸMYAPI"

    def _check_dependencies(self):
        """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
        missing_deps = []
        
        if not HAS_NUMPY:
            missing_deps.append("numpy")
        
        if not HAS_PIL:
            missing_deps.append("Pillow")
            
        if not HAS_REQUESTS:
            missing_deps.append("requests")
            
        return missing_deps

    def _debug_image_info(self, image):
        """æ‰“å°å›¾åƒä¿¡æ¯ç”¨äºè°ƒè¯•"""
        try:
            if image is None:
                return "Image is None"
            
            if HAS_TORCH and isinstance(image, torch.Tensor):
                return f"PyTorch Tensor: shape={image.shape}, dtype={image.dtype}, device={image.device}, min={image.min().item() if image.numel() > 0 else 'N/A'}, max={image.max().item() if image.numel() > 0 else 'N/A'}"
            elif HAS_NUMPY and isinstance(image, np.ndarray):
                return f"NumPy array: shape={image.shape}, dtype={image.dtype}, min={image.min()}, max={image.max()}"
            elif HAS_PIL and isinstance(image, Image.Image):
                return f"PIL Image: size={image.size}, mode={image.mode}"
            else:
                return f"Unknown type: {type(image)}"
        except Exception as e:
            return f"Error getting image info: {str(e)}"

    def _encode_image_to_base64(self, image):
        """å°†å›¾åƒç¼–ç ä¸ºbase64æ ¼å¼"""
        try:
            # æ£€æŸ¥ä¾èµ–
            if not HAS_PIL:
                raise ImportError("ç¼ºå°‘å¿…è¦çš„ä¾èµ–: Pillow")
                
            if not HAS_NUMPY and not HAS_TORCH:
                raise ImportError("ç¼ºå°‘å¿…è¦çš„ä¾èµ–: numpy æˆ– torch")
                
            print(f"Processing image: {self._debug_image_info(image)}")
            
            if image is None:
                raise ValueError("Image is None")
            
            # å¤„ç†PyTorchå¼ é‡
            if HAS_TORCH and isinstance(image, torch.Tensor):
                print("Converting PyTorch tensor to NumPy array")
                # ç¡®ä¿å¼ é‡åœ¨CPUä¸Šå¹¶è½¬æ¢ä¸ºnumpy
                if image.is_cuda:
                    image = image.cpu()
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                image = image.numpy()
                print(f"Converted to NumPy array: shape={image.shape}, dtype={image.dtype}")
                
            # å¤„ç†ComfyUIçš„å›¾åƒæ ¼å¼ï¼ˆé€šå¸¸æ˜¯æµ®ç‚¹æ•°numpyæ•°ç»„ï¼‰
            if HAS_NUMPY and isinstance(image, np.ndarray):
                # å¤„ç†æ‰¹å¤„ç†ç»´åº¦
                if len(image.shape) == 4:
                    if image.shape[0] == 1:  # å•å¼ å›¾ç‰‡çš„æ‰¹å¤„ç†
                        image = image[0]
                    else:
                        # å¤šå¼ å›¾ç‰‡ï¼Œåªä½¿ç”¨ç¬¬ä¸€å¼ 
                        print(f"Warning: Received batch of {image.shape[0]} images, using only the first one")
                        image = image[0]
                
                # ç¡®ä¿å›¾åƒæ˜¯3é€šé“çš„
                if len(image.shape) == 3:
                    # æ£€æŸ¥é€šé“æ•°
                    if image.shape[2] == 3:  # RGB
                        pass  # ä¸éœ€è¦è½¬æ¢
                    elif image.shape[2] == 4:  # RGBA
                        # åªä¿ç•™RGBé€šé“
                        image = image[:, :, :3]
                    elif image.shape[2] == 1:  # ç°åº¦
                        # è½¬æ¢ä¸º3é€šé“
                        image = np.repeat(image, 3, axis=2)
                    else:
                        raise ValueError(f"Unsupported number of channels: {image.shape[2]}")
                else:
                    raise ValueError(f"Unsupported image shape: {image.shape}")
                
                # ç¡®ä¿å€¼èŒƒå›´åœ¨0-255ä¹‹é—´
                if image.dtype == np.float32 or image.dtype == np.float64:
                    if image.max() <= 1.0:
                        image = (image * 255).astype(np.uint8)
                    else:
                        image = image.astype(np.uint8)
                
                # è½¬æ¢ä¸ºPILå›¾åƒ
                pil_image = Image.fromarray(image.astype(np.uint8), 'RGB')
            
            elif HAS_PIL and isinstance(image, Image.Image):
                pil_image = image
                # ç¡®ä¿æ˜¯RGBæ¨¡å¼
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
            else:
                raise ValueError(f"Unsupported image type: {type(image)}")
            
            # é™åˆ¶åŸå§‹å›¾åƒä½“ç§¯ï¼Œé¿å…Base64åè¶…è¿‡10MB
            max_bytes = 10 * 1024 * 1024
            target_raw_bytes = int(max_bytes * 0.7)  # çº¦7MB
            min_dim = 512

            def save_to_buffer(img, fmt="JPEG", **save_kwargs):
                buf = io.BytesIO()
                img.save(buf, format=fmt, **save_kwargs)
                return buf, buf.tell()

            buffer, raw_size = save_to_buffer(pil_image, "JPEG", quality=95, optimize=True)
            if raw_size > target_raw_bytes:
                print(f"Warning: Image raw size ({raw_size / 1024 / 1024:.2f}MB) exceeds target {target_raw_bytes / 1024 / 1024:.2f}MB. Compressing...")

            resize_attempts = 0
            while raw_size > target_raw_bytes and (pil_image.width > min_dim or pil_image.height > min_dim) and resize_attempts < 5:
                scale_factor = max((target_raw_bytes / raw_size) ** 0.5, 0.3)
                new_width = max(int(pil_image.width * scale_factor), min_dim)
                new_height = max(int(pil_image.height * scale_factor), min_dim)
                if new_width == pil_image.width and new_height == pil_image.height:
                    new_width = max(int(pil_image.width * 0.75), min_dim)
                    new_height = max(int(pil_image.height * 0.75), min_dim)
                pil_image = pil_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
                resize_attempts += 1
                print(f"Resized image attempt {resize_attempts}: {new_width}x{new_height}")
                buffer, raw_size = save_to_buffer(pil_image, "JPEG", quality=90, optimize=True)

            quality = 90
            jpeg_attempts = 0
            while raw_size > target_raw_bytes and quality >= 40:
                buffer, raw_size = save_to_buffer(pil_image, "JPEG", quality=quality, optimize=True)
                jpeg_attempts += 1
                print(f"JPEG compression attempt {jpeg_attempts}: quality={quality}, size={raw_size / 1024 / 1024:.2f}MB")
                quality -= 5

            if raw_size > target_raw_bytes:
                raise ValueError(f"Image is too large even after compression ({raw_size / 1024 / 1024:.2f}MB). Please use a smaller image or resize manually.")

            buffer.seek(0)
            img_bytes = buffer.getvalue()
            img_str = base64.b64encode(img_bytes).decode('utf-8')
            base64_size_mb = len(img_str) / 1024 / 1024
            print(f"Final raw size: {raw_size / 1024 / 1024:.2f}MB, base64 size: {base64_size_mb:.2f}MB")
            print(f"Successfully encoded image to base64 (length: {len(img_str)})")
            return img_str
            
        except Exception as e:
            print(f"Error encoding image: {str(e)}")
            print(traceback.format_exc())
            raise

    def _generate_request_id(self, seed=None):
        """ç”Ÿæˆè¯·æ±‚IDï¼Œå¯ä»¥åŸºäºç§å­å€¼"""
        timestamp = int(time.time() * 1000)
        
        # å¦‚æœæä¾›äº†ç§å­å€¼ï¼Œä½¿ç”¨å®ƒæ¥ç”Ÿæˆéšæœºå­—ç¬¦ä¸²
        if seed is not None:
            # ä½¿ç”¨ç§å­åˆå§‹åŒ–éšæœºç”Ÿæˆå™¨
            local_random = random.Random(seed)
            random_str = ''.join(local_random.choices(string.ascii_letters + string.digits, k=8))
        else:
            # å¦åˆ™ä½¿ç”¨æ™®é€šéšæœº
            random_str = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
            
        return f"{timestamp}-{random_str}"

    def process(self, api_key, model, prompt, max_completion_tokens=65535, temperature=1.0, top_p=0.7, seed=0, reasoning_effort="minimal", image=None, image_2=None):
        """ä¸»å¤„ç†å‡½æ•°"""
        # åº”ç”¨ç§å­å€¼
        if seed == 0:  # 0è¡¨ç¤ºä½¿ç”¨å½“å‰ç§å­
            seed = self.current_seed
        
        # æ£€æŸ¥ä¾èµ–
        missing_deps = self._check_dependencies()
        if missing_deps:
            return (f"Error: ç¼ºå°‘å¿…è¦çš„ä¾èµ–: {', '.join(missing_deps)}. è¯·å®‰è£…è¿™äº›ä¾èµ–åå†è¯•ã€‚",)
            
        try:
            print(f"[DoubaoMMM] Processing request with model: {model}")
            print(f"[DoubaoMMM] Image 1 provided: {image is not None}")
            print(f"[DoubaoMMM] Image 2 provided: {image_2 is not None}")
            print(f"[DoubaoMMM] Using seed: {seed}")
            print(f"[DoubaoMMM] Reasoning effort: {reasoning_effort}")
            
            # è·å–å®é™…ä½¿ç”¨çš„APIå¯†é’¥
            actual_api_key = self._get_api_key(api_key)
            if not actual_api_key:
                return ("Error: è¯·è¾“å…¥APIå¯†é’¥æˆ–åœ¨config.jsonä¸­é…ç½®doubao_api_keyã€‚è¯·è®¿é—® https://console.volcengine.com/ark è·å–APIå¯†é’¥ã€‚",)
            
            # ä½¿ç”¨è±†åŒ…APIï¼Œé’ˆå¯¹æ·±åº¦æ€è€ƒæ¨¡å‹è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
            # 1.8ç‰ˆæœ¬æ”¯æŒreasoning_effortï¼Œå¯èƒ½éœ€è¦æ›´é•¿çš„å¤„ç†æ—¶é—´
            timeout_value = 1800 if "1-8" in model or "1-6" in model else 60

            print(f"[DoubaoMMM] Calling Doubao API with model: {model}")
            
            # ä½¿ç”¨æ ‡å‡†çš„ /api/v3/chat/completions ç«¯ç‚¹ï¼ˆæ”¯æŒæ‰€æœ‰å‚æ•°ï¼‰
            url = "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {actual_api_key}"
            }
            
            # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼ˆæ”¯æŒOpenAIå…¼å®¹æ ¼å¼ï¼‰
            user_content = []
            
            # å¤„ç†å›¾åƒè¾“å…¥ï¼ˆæ”¯æŒä¸¤å¼ å›¾åƒï¼‰
            if image is not None:
                try:
                    print(f"Processing image 1 for API...")
                    image_base64 = self._encode_image_to_base64(image)
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    })
                    print("Successfully added image 1 to message")
                except Exception as e:
                    print(f"Error processing image 1: {str(e)}")
                    print(traceback.format_exc())
                    return (f"Error processing image 1: {str(e)}",)
            
            if image_2 is not None:
                try:
                    print(f"Processing image 2 for API...")
                    image2_base64 = self._encode_image_to_base64(image_2)
                    user_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image2_base64}"
                        }
                    })
                    print("Successfully added image 2 to message")
                except Exception as e:
                    print(f"Error processing image 2: {str(e)}")
                    print(traceback.format_exc())
                    return (f"Error processing image 2: {str(e)}",)
            
            # æ·»åŠ æ–‡æœ¬æç¤º
            user_content.append({"type": "text", "text": prompt})
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{
                "role": "user",
                "content": user_content
            }]
            
            # æ„å»ºè¯·æ±‚payload
            payload = {
                "model": model,
                "messages": messages
            }
            
            # æ·»åŠ max_completion_tokensï¼ˆæ”¯æŒæ‰€æœ‰ç‰ˆæœ¬ï¼‰
            if max_completion_tokens and max_completion_tokens > 0:
                payload["max_completion_tokens"] = max_completion_tokens
            
            # 1.8ç‰ˆæœ¬æ·»åŠ reasoning_effortå‚æ•°
            is_1_8_model = "1-8" in model or "251228" in model
            if is_1_8_model:
                if reasoning_effort:
                    payload["reasoning_effort"] = reasoning_effort
                    print(f"[DoubaoMMM] Reasoning effort: {reasoning_effort}")
            else:
                # å¯¹äºå…¶ä»–ç‰ˆæœ¬ï¼Œæ·»åŠ  temperature å’Œ top_p å‚æ•°
                payload["temperature"] = temperature
                payload["top_p"] = top_p
            
            print(f"[DoubaoMMM] APIç«¯ç‚¹: {url}")
            print(f"[DoubaoMMM] è¯·æ±‚payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
            
            # ç¦ç”¨ä»£ç†ï¼Œå› ä¸ºè±†åŒ…æ˜¯å›½å†…æœåŠ¡ï¼Œé€šå¸¸ä¸éœ€è¦ä»£ç†
            # å¦‚æœç³»ç»Ÿè®¾ç½®äº†ä»£ç†ä½†ä»£ç†ä¸å¯ç”¨ï¼Œä¼šå¯¼è‡´è¿æ¥å¤±è´¥
            resp = requests.post(
                url, 
                headers=headers, 
                json=payload, 
                timeout=timeout_value,
                proxies={"http": None, "https": None}  # ç¦ç”¨ä»£ç†
            )
            print(f"[DoubaoMMM] Response status code: {resp.status_code}")
            if not resp.ok:
                try:
                    err_json = resp.json()
                    err_message = err_json.get('error', {}).get('message', resp.text)
                except Exception:
                    err_message = resp.text
                # é’ˆå¯¹å¸¸è§é”™è¯¯ç»™å‡ºæç¤º
                if resp.status_code == 401:
                    return ("Error: èº«ä»½éªŒè¯å¤±è´¥(401)ã€‚è¯·ç¡®è®¤ config.json ä¸­çš„ doubao_api_key æ­£ç¡®ä¸”æœªåŒ…å«å¤šä½™ç©ºæ ¼ã€‚è‹¥ä»å¤±è´¥ï¼Œè¯·ç›´æ¥ç”¨è¯¥ key ä»¥ cURL è°ƒç”¨éªŒè¯ã€‚",)
                elif resp.status_code == 404:
                    error_detail = f"æ¨¡å‹ '{model}' ä¸å­˜åœ¨æˆ–æ‚¨æ²¡æœ‰è®¿é—®æƒé™ã€‚\n"
                    error_detail += f"è¯·æ£€æŸ¥ï¼š\n"
                    error_detail += f"1. æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®\n"
                    error_detail += f"2. æ‚¨çš„è´¦æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®è¯¥æ¨¡å‹\n"
                    error_detail += f"3. æ¨¡å‹æ˜¯å¦å·²å‘å¸ƒæˆ–éœ€è¦ç‰¹æ®Šç”³è¯·\n"
                    error_detail += f"4. å¯å°è¯•ä½¿ç”¨å…¶ä»–å¯ç”¨æ¨¡å‹ï¼šdoubao-seed-1-6-vision-250815 æˆ– doubao-seed-1-6-251015\n"
                    error_detail += f"\nåŸå§‹é”™è¯¯: {err_message}"
                    return (f"Error: {resp.status_code} - {error_detail}",)
                return (f"Error: {resp.status_code} - {err_message}",)
            
            result = resp.json()
            print(f"[DoubaoMMM] Response: {json.dumps(result, ensure_ascii=False, indent=2)}")
            
            # è§£æå“åº”ï¼ˆ/api/v3/chat/completions æ ‡å‡†æ ¼å¼ï¼‰
            if "choices" in result and len(result["choices"]) > 0:
                response_text = result["choices"][0]["message"]["content"]
            else:
                # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›å®Œæ•´å“åº”ä¾›è°ƒè¯•
                response_text = json.dumps(result, ensure_ascii=False, indent=2)
                print(f"[DoubaoMMM] Warning: æ— æ³•è§£æå“åº”æ ¼å¼ï¼Œè¿”å›å®Œæ•´JSONä¾›è°ƒè¯•")

            # æ›´æ–°ç§å­
            self.current_seed = seed

            return (response_text,)
            
        except Exception as e:
            print(f"Unexpected error in process: {str(e)}")
            print(traceback.format_exc())
            return (f"Error: {str(e)}",)







NODE_CLASS_MAPPINGS = {
    "DoubaoNode": DoubaoNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DoubaoNode": "ğŸ¥Ÿè±†åŒ…MMM"
}