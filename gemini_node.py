import os
import json

# ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹é…ç½®
def load_gemini_models_from_config():
    """ä»config.jsonåŠ è½½Geminiæ¨¡å‹é…ç½®"""
    try:
        config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            models = config.get('models', {})
            gemini_models = models.get('gemini', {})
            # ç§»é™¤é»˜è®¤æ¨¡å‹å›é€€
            return gemini_models
    except Exception as e:
        print(f"Error loading Gemini models from config: {str(e)}")
        # ä¸å†æä¾›é»˜è®¤æ¨¡å‹
        return {}

# åŠ è½½æ¨¡å‹é…ç½®
GEMINI_MODELS = load_gemini_models_from_config()

class GeminiAINode:
    def __init__(self):
        self.config_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "config.json")
        self.api_key = self._load_api_key()
        
    def _load_api_key(self):
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config.get('gemini_api_key', '')
        except Exception as e:
            print(f"Error loading Gemini API key: {str(e)}")
            return ''

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (list(GEMINI_MODELS.keys()),),
                "prompt": ("STRING", {"multiline": True, "default": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œä¸è¦åšå‡ºè¯„è®ºæˆ–å»ºè®®"}),
                "max_tokens": ("INT", {"default": 1024, "min": 1, "max": 8192}),
                "temperature": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0}),
                "top_p": ("FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0}),
                "top_k": ("INT", {"default": 40, "min": 1, "max": 100}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0x7fffffff}),
            },
            "optional": {
                "image": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("STRING",)
    FUNCTION = "process"
    CATEGORY = "ğŸMYAPI"

    def process(self, model, prompt, max_tokens=1024, temperature=1.0, top_p=0.95, top_k=40, seed=0, image=None):
        """ä¸»å¤„ç†å‡½æ•°"""
        
        if not self.api_key:
            return ("Error: è¯·åœ¨config.jsonä¸­é…ç½®gemini_api_keyã€‚è¯·è®¿é—® https://aistudio.google.com/ è·å–APIå¯†é’¥ã€‚",)
        
        try:
            # æ£€æŸ¥google-genaiæ˜¯å¦å¯ç”¨
            from google import genai
            from google.genai import types
        except ImportError:
            return ("Error: è¯·å®‰è£…google-genai: pip install google-genai",)
        
        try:
            print(f"Processing request with Gemini model: {model}")
            print(f"Image provided: {image is not None}")
            print(f"Using seed: {seed}")
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = genai.Client(api_key=self.api_key)
            
            # å‡†å¤‡å†…å®¹
            contents = [prompt]
            
            # ç®€å•çš„å›¾åƒå¤„ç†
            if image is not None:
                try:
                    from PIL import Image
                    import numpy as np
                    import torch
                    
                    # ç®€åŒ–å¤„ç†ï¼Œä¸minimalç‰ˆæœ¬ç›¸åŒ
                    if isinstance(image, torch.Tensor):
                        if image.is_cuda:
                            image = image.cpu()
                        image = image.numpy()
                    
                    if len(image.shape) == 4:
                        image = image[0]
                    
                    if image.dtype in [np.float32, np.float64] and image.max() <= 1.0:
                        image = (image * 255).astype(np.uint8)
                    
                    pil_image = Image.fromarray(image.astype(np.uint8), 'RGB')
                    contents.insert(0, pil_image)
                    print("Successfully added image to content")
                    
                except Exception as e:
                    return (f"Error processing image: {str(e)}",)

            # ç”Ÿæˆé…ç½®
            config = types.GenerateContentConfig(
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                max_output_tokens=max_tokens,
                seed=seed if seed != 0 and seed <= 0x7fffffff else None
            )

            # è°ƒç”¨API
            print(f"Calling Gemini API with model: {model}")
            response = client.models.generate_content(
                model=model,
                contents=contents,
                config=config
            )

            return (response.text,)
            
        except Exception as e:
            print(f"Unexpected error in Gemini process: {str(e)}")
            return (f"Error: {str(e)}",)

NODE_CLASS_MAPPINGS = {
    "GeminiAINode": GeminiAINode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiAINode": "ğŸŒŸGemini AI"
}